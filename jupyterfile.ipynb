{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 214ms/step - accuracy: 0.0309 - loss: 3.3291 - val_accuracy: 0.1600 - val_loss: 3.1305\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.2535 - loss: 2.9882 - val_accuracy: 0.8400 - val_loss: 2.4652\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6107 - loss: 2.4199 - val_accuracy: 0.8400 - val_loss: 1.4479\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7622 - loss: 1.6368 - val_accuracy: 0.8400 - val_loss: 1.0404\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7924 - loss: 1.2023 - val_accuracy: 0.8400 - val_loss: 1.1080\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8205 - loss: 1.1891 - val_accuracy: 0.8400 - val_loss: 1.1516\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7465 - loss: 1.6181 - val_accuracy: 0.8400 - val_loss: 1.1001\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7715 - loss: 1.3919 - val_accuracy: 0.8400 - val_loss: 1.0744\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7611 - loss: 1.2842 - val_accuracy: 0.8400 - val_loss: 1.0881\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7590 - loss: 1.3835 - val_accuracy: 0.8400 - val_loss: 1.0940\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9062 - loss: 0.7225\n",
      "Test Accuracy: 0.91\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step\n",
      "Predicted Verse Reference: nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"C:\\\\Users\\\\USER\\\\Downloads\\\\bible_passage_finder\\\\BIble passage data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract relevant columns\n",
    "data = data[['BIBLE TEXT', 'VERSE']] # Keep only non-null rows in both columns\n",
    "texts = data['BIBLE TEXT'].astype(str).values\n",
    "labels = data['VERSE'].astype(str).values\n",
    "\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "max_seq_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_seq_length)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( padded_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word_index) + 1, output_dim=128, input_length=max_seq_length),\n",
    "    SimpleRNN(128, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "def predict_verse(input_text, model, tokenizer, label_encoder, max_seq_length):\n",
    "    # Preprocess the input text\n",
    "    preprocessed_text = preprocess_text(input_text, tokenizer, max_seq_length)\n",
    "    \n",
    "    # Debug: Check if preprocessed text is empty\n",
    "    if preprocessed_text.sum() == 0:\n",
    "        return \"Error: Input contains only out-of-vocabulary words!\"\n",
    "\n",
    "    # Predict the label\n",
    "    prediction = model.predict(preprocessed_text)\n",
    "    predicted_class = prediction.argmax(axis=1)[0]\n",
    "\n",
    "    # Debug: Check if predicted class is within range\n",
    "    if predicted_class >= len(label_encoder.classes_):\n",
    "        return \"Error: Predicted class is out of range!\"\n",
    "    \n",
    "    # Decode the predicted label to get the verse reference\n",
    "    predicted_verse = label_encoder.inverse_transform([predicted_class])[0]\n",
    "    return predicted_verse\n",
    "input_text = ''\n",
    "\n",
    "# Predict the verse reference\n",
    "predicted_verse = predict_verse(input_text, model, tokenizer, label_encoder, max_seq_length)\n",
    "print(f\"Predicted Verse Reference: {predicted_verse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
      "Predicted Verse Reference: nan\n"
     ]
    }
   ],
   "source": [
    "# Define a function for preprocessing\n",
    "def preprocess_text(input_text, tokenizer, max_seq_length):\n",
    "    # Tokenize and pad the input text\n",
    "    sequence = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_seq_length)\n",
    "    return padded_sequence\n",
    "\n",
    "# Define a function for prediction\n",
    "def predict_verse(input_text, model, tokenizer, label_encoder, max_seq_length):\n",
    "    # Preprocess the input text\n",
    "    preprocessed_text = preprocess_text(input_text, tokenizer, max_seq_length)\n",
    "    \n",
    "    # Predict the label\n",
    "    prediction = model.predict(preprocessed_text)\n",
    "    predicted_class = prediction.argmax(axis=1)[0]\n",
    "    \n",
    "    # Decode the predicted label to get the verse reference\n",
    "    predicted_verse = label_encoder.inverse_transform([predicted_class])[0]\n",
    "    return predicted_verse\n",
    "\n",
    "# Example input text\n",
    "input_text = 'habakkuk chapter 2 from verse 1 to 3. [Music] i will stand upon my watch and set me upon the tower and we watch to see what he will say unto me and what i shall answer when i am reproved and the lord answered me i say right division and make it plain upon tables that he may wrong that readeth it for division is yet for an appointed time but at the end it shall speak and not lie do italy wait for it because it will surely come it will not tarry [Applause] all the promises of god for you will come to pass tonight'\n",
    "\n",
    "# Predict the verse reference\n",
    "predicted_verse = predict_verse(input_text, model, tokenizer, label_encoder, max_seq_length)\n",
    "print(f\"Predicted Verse Reference: {predicted_verse}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
